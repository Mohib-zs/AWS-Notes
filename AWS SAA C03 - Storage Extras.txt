AWS Snowball is a highly secure portable device to collect and process data at the edge, and migrate data in and out of AWS. AWS Snowball provides a Import case with a physical device, device is given to client (us) to transfer data in it, the device is then shipped back to AWS and they upload the data from the device to the service (e.g S3). The export case is where device is given to us, then we load the data we want in the device and ship it back to AWS for them to load the data to S3. Variants in Snowball are Snowball edge storage optimized with about 80TB usable storage while Snowball Edge Compute Optimized has more compute and maybe a GPU with about 42TB usable storage. 

Also need to provide the KMS key to encrypt the data to be exported/imported. A service role is also provided to Snow family device to access the needed resources. (e.g write to S3 and publish to SNS)

There is a third local compute case or Edge Computing which means processing data closer to where itâ€™s generated (factories, ships, remote sites) instead of sending it all to the cloud first. Snowball Edge runs compute workloads locally using:

EC2 instances (same AMIs as in AWS cloud)

AWS Lambda functions

IoT Greengrass

This allows real-time processing before data transfer. Useful in low or no internet connectivity areas.

Snowball cannot directly import to Glacier, you must import first to S3 then use lifecycle policies to transistion the S3 to glacier.

Amazon FSx allows you to launch 3rd party high performance file systems on AWS, they're fully managed and the main four are FSx for 'x' (x=[Lustre, NetApp ONTAP, Windows File Server, OpenZFS])

FSx for Windows is a fully managed windows FS which supports SMB protocol & Windows NTFS along with Microsoft AD integration, ACLs, user quotas. Can be mounted on linux EC2 instances. Supports Microsoft Distributed File System (DFS) Namespaces (group files across multiple FS). Scale upto 10s of GB/s, millions of IOPS, 100s PB of data. Storage options are SSD for sensitive workload (databases, media streams, data analytics) and HDD broad spectrum of workloads (home directory, CMS,..) Can be accessed from your on-premises infrastructure (VPN or Direct Connect) and can be configured to be multi-AZ. Data is backed up daily to S3.

FSx for Lustre is a parallel distributed file system for large scale computing. The name Lustre is derived from "Linux" and "cluster". Used for Machine Learning and High Performance Computing (HPC), video processing, financial modeling, Electronic Design Automation. Scales upto 100s GB/s, million of IOPS, sub-ms latencies. Storage Options are SSD (for small & random files) and HDD (large & sequential files). Seamless integration with S3 that can read S3 as a file system via FSx and write the output of computations back to S3 (through FSx). Can be used from on-premises servers (VPN or Direct Connect) 

Two deployment types with FSx, first is scratch FS which is temporary storage, data is not replicated (doesn't persist if file server fails) high burst (6x faster, 200 MBps per TiB) used for short term processing, optimize costs. Second is persistent file system for long-term storage, Data is replicated within same AZ and replace failed files within minutes. Used for long-term processing, sensitive data.

FSx for NetApp ONTAP is a managed NetApp ONTAP on AWS, File system compatible with NFS, SMB, iSCSI protocol and move workloads running on ONTAP or NAS to AWS. Works with linux, windows, MacOS, VMware Cloud on AWS, Amazon Workspaces & AppStream 2.0 and EC2, ECS and EKS. Storage shrinks or grows automatically. Provides snapshots, replication, its low cost, and also has compression and data de-duplication (find duplicates in FS). Point in time instantaneous cloning (helps in testing workloads). 

FSx for OpenZFS is a managed OpenZFS file system on AWS, its compatible with NFS (v3, v4, v4.1, v4.2) used to move workloads on ZFS to AWS. Has broad compatibility like NetApp ONTAP, its faster as it can go upto 1 million IOPS with < 0.5 ms latency. Same features like snapshots, compression, low cost, point in time instantaneous cloning but doesnt have de-duplication.

Storage gateways are used in hybrid cloud solutions, serving as a bridge between storage servers/services between cloud and on-prem environments. Following are main types of storage gateway.

S3 File gateway uses configured S3 buckets which are accessible using the NFS and SMB protocol, most recently used data is cached in the file gateway. Supports S3 standard, S3 standard IA, S3 One Zone A and S3 intelligent tiering (not glacier). For glacier, transition to S3 glacier using a lifecycle policy. Bucket access using IAM roles for each file gateway. SMB protocol has integration with AD for user authentication.

Volume gateway is block storage using iSCSI protocol backed by S3, backed by EBS snapshots which can help restore on-premises volumes. Cached volumes means low latency access to mostg recent data. Stored volumes means entire data is on-premises, scheduled backups to S3.

Tape gateway means some companies have backup processes using physical tapes. With tape gateway, companies use the same processes but, in the cloud. Virtual Tape library (VTL) backed by S3 and Glacier. Back up data using existing tape-based processes (and iSCSI interface) Works with leading backup software vendors.

Storage gateway has host platforms in the form of VMware ESXi, Hyper-V, Linux KVM, Amazon EC2 or a hardware applicance for on-prem virtualization required for storage gateway. For hardware appliance you have to buy it from amazon.com. It works with File, Volume and Tape gateway. Has the required CPU, memory, network, SSD cache resources and helpgul for daily NFS backups in small data centers. 

Remember that user/group file shares can talk to file gateway (vm or appliance) using only NFS/SMB protocol, on-prem servers can talk to volume gateway via iSCSI and iSCSI VTL to tape gateway. Then from file gateway it goes to storage gateway (middle man) via encryption intransit (internet or direct connect) then to cloud (S3 excluding glacier.)

AWS Transfer family is a managed service for file transfers in and out of S3 or EFS using FTP protocol. Supported ones are FTP, FTPS, SFTP. Managed infrastructure which is scalable, reliable, and HA (multi-az). Pay per provisioned endpoint per hour + data transfer in GB. Store and manage user credentials within the service or integrate with other auth services like microsoft AD, LDAP, Cognito etc. Use cases are sharing files, public datasets, CRM, ERP etc. You can use a GNS using Route 53 optionally to give your own hostname, then do FTP via Transfer family with IAM Role to access S3 or EFS.

AWS datasync is used to move large amounts of data to and from locations, like from on-prem servers/ other cloud to AWS and it uses NFS, SMB, HDFS, S3 API.. protocols (Needs agent to be installed). Also move AWS to AWS (different services and doesnt need agent). Can synchronize to S3, EFS or FSx. Replication is scheduled (daily, weekly) not continuous. Only data transfer service which preserves the metadata and file permissions of the files/data transfered (like for NFS, POSIX, SMB etc. type of FS Protocols). One datasync agent can use upto 10 Gbps, so setup a bandwidth limit. DataSync also allows us to sync data from Cloud to On-prem as well which is another benefit of it.

In exam, you maybe asked that we want to use DataSync but dont have bandwidth, answer is to use Snowcone with datasync agent pre-installed in it, use it to sync the data and export it back to AWS and it would be exported.

S3 Object Storage