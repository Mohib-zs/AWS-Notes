CloudWatch provides metrics for every services in AWS, Metrics (CPU Utilization, Network) belong to namespaces and a Dimension is an attribute of a metric (instance id, env etc..) and you can have upto 30 dimensions per metric. Metrics have time stamps and e.g of custom CloudWatch metrics are RAM utilization of Ec2 instance. For continuous streaming of CloudWatch metrics into target destinations with "near-real-time delivery" and low latency, use CW Metric streams and targets can be Firehose or 3rd party SaaS like DataDog, Splunk, New Relic etc. Can also filter metrics to stream a subset only. 

In CloudWatch Logs, Log groups are an arbitrary name, usually for an app and Log streams are instances within app/log files/containers. You can define log expiration policies (never expire, 1 day to 10 years). CloudWatch Logs can send logs to S3 (exports), Kinesis Data Streams, Firehose, Lambda, OpenSearch. Logs are encrypted by default and you can setup KMS-based encryption with your own keys. CloudWatch Log sources are SDK, CloudWatch Logs Agent or Unified agent, Elastic Beanstalk, ECS, Lambda, VPC Flow Logs, API Gateway, CloudTrail based on filter, Route53 (For DNS Insights). CW Log Insights provide a purpose-built query language to search and analyze log data based on conditions, desired fields or filters (like find a specific ip or number of "ERROR" occurrences in your logs). CW Insights can query multiple log groups in different AWS accounts, can save queries to CW dashboards. Its a query engine not a real-time engine. CW Logs Subscriptions allows is to get real-time log events from CW logs for processing and analysis. Send to KDS (and then to Firehose, KDA, EC2, Lambda), Firehose (and from there to S3 in near-real-time) or Lambda (and then to OpenSearch service in real-time). CW Log Aggregation for multi-account where CW Logs send to subscription filters of their respective accounts to a single KDS, from their to Firehose which send near-real-time data to S3. Though a Destination Access policy is required for sender account to send log data to receiver account, and an IAM role is needed for the subscription destination to send data to KDS (role should be cross-account assumable by sender account). Subscriptions fiters (SF) includ ElasticSearch SF, Kinesis SF, Firehose SF, Lambda SF. Use live-tail to see the logs in detail like the time they were created and from which stream.

CW Logs Agents: By default no logs from your ec2 will go to CloudWatch, need to run an agent on EC2 to push the log files you want. Ec2 must also have IAM role so the sent logs can be shown in CW Logs. CW log agent can be setup on-prem as well. However CW logs agent is a old version which can only send logs. CW Unified agent collects and sends additional info (metrics) like RAM, process etc. Also sends logs to CW logs obv, and all your CW unified agents can have their configuration centralized via SSM parameter store. CW Unified Agent collected metrics in form of CPU (active, guest, idle) or Disk Metrics (free, used, total) Disk IO (writes, reads, bytes, iops) RAM (free, inactive, used) Netstat (number of TCP and UDP connections, net packets) Processes (total, dead, sleep) Swap Space (free, used %). Out-of-the-box for EC2 is disk, CPU, network.

Alarms trigger notifications for metrics with options like min, max sampling etc. Alarm States are OK, INSUFFICIENT_DATA (not enough data to trigger alarm) and ALARM (threshold exceeded). Period is length of time in seconds with High resolution custom metrics like 10 sec, 30 sec or multiples of 60 sec. CW Alarm Targets stop, terminate, reboot or recover and EC2 instance. Trigger Auto-scaling or send notification to SNS (to do pretty much anything we want). However CW Alarms are on a single metric, for multiple metrics, use composite alarms that monitor the state of other alarms. They use AND and OR conditions. Helpful to reduce "alarm noise" by creating complex composite alarms. e.g for an EC2, composite alarms monitors the alarms monitoring for CPU and IOPS, in an AND condition, both alarms must trigger for the composite to trigger as well to trigger SNS. EC2 instance recovery includes CW Alarms check for instance status, system status (hardware state), Attached EBS status, if alarms is triggered, it host changes from A to B while keeping the same private, public IP, metadata and placement group.

Amazon EventBridge is used to schedule cron jobs for an event for every hour and on each cron, a Lambda function is used to trigger a script. Event pattern has event rules which react to a service doing something, e.g IAM Root user sign in event will send a message to SNS topic which will send an Email notification. Lambda, SQS, SNS mostly used to trigger by events. Event sources can be EC2 (start/stop events), Code Build (failed build event), S3 (object upload event), Trusted advisor (new finding), CloudTrail (to intercept any API call made within your AWS Accounts, which is huge) or schedule cron events (every 2 hours). These events can be filtered before sent to eventbridge. Event Desitnations can be Lambda (to run a piece of code), AWS Batch (to perform batch operations), ECS Task, SQS/SNS, Kinesis Data Streams, Step Functions, Code Pipeline or Build, EC2 Actions (restart an instance). Event Buses are used to send events to eventbridge, Default bus for AWS services, Partner Bus for AWS SaaS Partners (DataDog, Zendesk, 0Auth) and custom buses for Custom apps to send events to event bridge. Event buses can be accessed by other accounts via resource-based-policies and you can archive event (all/filter) to an event bus (indefinitely or set period). Ability to replay archived events. Eventbridge - Schema registry allows you to generate code for your application, that will know in advance how data is structured in the event bus, schemas can be versioned so you can iterate between the schemas. Resource based policies allows us to send events from different account in a centralized manner, Use cases is to aggregate all events from your AWS Organization in a single AWS account/region.

CW Container Insights collect, aggregate and summarize metrics, logs from containers, these containers can be in ECS, EKS, Kubernetes on EC2, Fargate (ECS & EKS) In EKS and Kubernetes, CW Insights is using a containerized version of CW agent to discover containers. CW Lambda Insights are monitoring and troubleshooting solution for serverless applications running on AWS Lambda. Collects, aggregates and summarizes system-level metrics including CPU, memory disk and network, does the same for diagnostic info such as cold starts and lambda worker shutdowns. Lambda Insights are provided as Lambda layer. CW Contributor Insights analyze log data and create time series that display contributor data. See metrics about top-N contributors. This helps you find the top talkers of your infra or who is impacting system performance. Works for any AWS-generated logs (VPC, DNS etc.) For e.g you can find bad hosts, the heaviest network users or find the URLS that generate most errors. Keyword for CW Contributor insights is "Top 10 Contributor". CW Application Insights provides automated dashboards that show potential problems with monitored apps to help isolates issues. Provides enhanced visibility in your app health to reduce the time it will take to troubleshoot and repair your applications. Apps running on EC2 with select technologies only (Java, .NET, IIS Web, databases) and you can use other AWS resources e.g EBS, RDS, ELB, ASG, Lambda, SQS, DynamoDB, s3, ECS, EKS, SNS, API Gateway. Automated dashboards are powered by SageMaker internally.

CloudTrail provides governance, compliance audit for your AWS account and is enabled by default. Allows you to get an history of events/API calls made within your AWS account by the console, SDK, CLI, AWS Services. Can put logs from CloudTrail into CloudWatch Logs or S3. Can be applied to all or a single region. If a resource is deleted, investigate CloudTrail first. C.Trail Events include Management Events, operations that are performed on resource in an AWS account (e.g Configuring routing rules, security via IAM, Deleting a resource). Management events are trailed by default by C.Trail. You can separate Read from Write events. Data Events are high volume events (e.g S3 PutObject, DeleteObject) that are not trailed by default, can separate read and write. Enable CloudTrail Insights to detect unusual activity in your account (e.g inaccurate provisioning, hitting service limits, Bursts of AWS IAM actions, Gaps in periodic maintenance activity) CloudTrail Insights analyze normal management events to create a baseline. Continuously analyzes write events to detect unusual patterns. Events are retained in CloudTrail for 90 days. For larger retention, export them to S3 and use Athena to query in S3. A great use case is to integrate EventBridge with CloudTrail for important event and their notifications (e.g if a SG has inbound rule added, the EC2 API call made to do this will go to CloudTrail, the event will be logged by eventbridge which will trigger SNS to send an email)

AWS Config helps with auditing and recording compliance of AWS resources, helps record configurations and changes over time. Questions solved by AWS Config include, is there unrestricted SSH Access? Do my buckets have public access? Has my ALB configs changed overtime? Receive SNS notifications for any changes. AWS Config is a per-region service. Can be aggregated across regions and accounts and a possibility of storing the config data into S3 (analyzed by Athena). Custom config rules must be defined in Lambda. AWS Config can't remediate by default, integrate it with SSM Automation Documents (AWS or custom) that invoke Lambda Function to perform remediation if NON_COMPLIANT event has occurred in Config.

