Deploying multiple applications/Services will require to communicate with each other. Services communicating directly with each other is all synchronous communication with no middleware. Services communicatitng to a queue is called asynchronous communication with a queue as middleware. Issue with sync comms is that if one services has a traffic spike, the whole app would crash. Async comms will decouple services so that if one fails, the rest work as is since they are talking to a queue rather than the service. For decoupling you can use SQS: Queue model; SNS: pub/sub model; Kinesis: real-time streaming model.

A queue basically takes messages from services called producers (like process a video or order), then services called consumers will pull the messages from the queue from the other end, once the message is processed, it gets deleted from the queue.

Amazon SQS - standard queue is the oldest offering (10 years old) and is a fully managed service used to decouple applications. SQS provides unlimited throughput, unlimited number of messages in queue, default retention of messages is 4 days and max 14 days, low latency of about <10ms on pub and receive. Limitation of 256KB per message sent. Can have duplicate messages (at least once delivery, occasionally), can have out of order messages (best effort ordering). Also provides FIFO type of queue as well.

Message is produced to SQS using the SDK (SendMessage API). The message is persisted in SQS until a consumer deletes it. Example send an order to be processed with custom attributes like order id, customer id etc. Message is consumed by consumers (e.g EC2, servers, Lambda), Consumer polls SQS for messages (receive upto 10 messages at a time) then process the messages (e.g insert an order into RDS) and finally delete the messages using the DeleteMessage API after processing. Multiple consumers receive and process messages in parallel. At least once delivery and best-effort message ordering is applied here. We can scale consumers horizontally to improve throughput of processing.

Using SQS with ASG is a great strategy with CloudWatch Metric attached to the SQS queue. CloudWatch will check for queue length (using ApproximateNumberOfMessages metric query) and will sound a CloudWatch alarm if the queue length breaches the limit, causing the ASG to increase the number of instances to manage the traffic spike or workload.

Another great usecase is to decouple a Front web-app for video processing into two ASG groups rather than using a single instance with ASG. The front-end layer of the app would take the requests (present in its own ASG and sized accordingly) and forward them to SQS which would then be received by the backend layer of the app for video processing in its own ASG (this one can have a GPU optionally) and then the processed video is stored in S3.

For security, SQS has encryption, using HTTPS API for in-flight and KMS keys at-rest (SSE-SQS or SSE-KMS). Client-side encryption if the client wants to perform encryption/decryption themselves (not supported out of the box). Access control's managed using IAM policies to regulate access to the SQS API. SQS Access Policies (similar to S3 bucket policies) are useful for cross-account access to SQS queues and are useful for alowing other services (SNS, S3..) to write to an SQS queue.

When a message is polled (pulled) by a consumer, it becomes invisible to other consumers. By default, the visibility timeout is 30 seconds meaning the message has 30 seconds to be processed. After the timeout is over and the message has not been deleted then it is put back into the queue (becomes visible again) to be polled by the same or different consumer. If the message gets polled again then it will be processed twice (causing duplicates). A consumer could prevent this by calling the ChangeMessageVisibility API to get more time. If visibility timeout is high (hours), and consumer crashes, re-processing will take time. If visibility is too low (seconds), we get duplicates. Best practice is to set the timeout to moderate time enough for the consumer to process and allow the consumer to call the ChangeMessageVisibility API if it needs more time.

When a consumer requests messages from the queue but there are none so it optionally waits for messages to arrive - this is called Long Polling. Long polling decreases the number of API calls made to SQS while increasing the efficiency and reducing latency of your application. Preferred wait time is between 1 to 20 seconds with 20 being preferred most. Long polling is preferable to Short Polling and Long polling can be enabled at the API level or queue level using WaitTimeSeconds.

SQS - FIFO Queue means ordering of messages in the queue. Like if producer sends messages in order [4,3,2,1] then the consumer polled messages would be in order [4,3,2,1]. Limited throughput with 300 msg/s without batching and 3000 msg/s with. Exactly-once send capability and removes all duplicates sent within the 5 minute range using deduplication ID. Messages are processed in order and ordering is done via Message Group ID (all messages in the same group are ordered) - mandatory parameter. The name of the queue must end with .fifo to use the FIFO ability.

Another use case of SQS is to use it as a buffer, suppose you have a e-commerce website, and on black Friday there are many transactions being done and all of them have to be written to a database (e.g RDS, Aurora, DynamoDB). Too many transactions needed to be inserted too fast may result in some of them being lost due to overload on DBs. Solution is to use SQS queue as middleware, the ASG would enqueue the transaction it receives as client request, sends it to SQS, give it to another ASG for dequeue and then the ASG writes inserts it to the DB. With SQS infinite throughput, this means all transaction will be written NMW.

Also remember whenever exam says something about decoupling or sudden spike load or timeout and need to scale really fast then do look at SQS queue.