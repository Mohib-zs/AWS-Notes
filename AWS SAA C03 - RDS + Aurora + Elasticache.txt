RDS is AWS managed DB service which uses SQL as a query language. Types of databases provided are:
- Postgres
- MySQL
- MariaDB
- Oracle
- Microsoft SQL Server 
- IBM DB2
- Aurora (AWS Proprietary database)

Advantages of using RDS versus deploying DB on EC2 is that RDS has automated provisioning and OS patching, continuous backups and restore to a specific timestamp (Point in time restore), Monitoring dashboards, Read replicas for improved read performance, Multi az setup for DR, Maintenance windows for upgrades, scalability (vertical & horizontal), EBS backed storage. 
Disadvantage is that you can SSH or access the underlying EC2 instance in which the database is running.
RDS auto scaling helps you increase storage on your RDS DB instance dynamically, meaning it will automatically scale out if the DB is low on storage without stopping. You avoid manually scaling the DB. You have to set the maximum storage threshold, for e.g Automatically modify if free storage is less than 10% of allocated storage, Low storage lasts atleast 5 minutes, 6 hours have passed since last modification. Useful for applications with unpredictable workloads and supports all RDS engines.

An RDS DB instance can have upto 15 read replicas within an AZ, Cross AZ or Cross Region. Replication is ASYNCHRONOUS so reads are eventually consistent but not immediate between the database instances, Replicas can be promoted to their own DB, Applications must update the connection string to leverage read replicas.

RDS read replica Use case is that lets say we have a prod database that is taking on load, we want to run a reporting app for some analytics, rather than attaching the prod database to the new reporting app you attach a read replica database of the prod database and attach it to the reporting app. This is because attaching prod database to both would overload prod database, so attaching read replica would allow both to run without issues. Just know that you can only run SELECT (=read) queires (SQL queries which are for reading not INSERT, UPDATE or DELETE) on read replicas.

There is usually network cost in AWS when data goes from one AZ to another. But there are exceptions sometimes for managed services including RDS. For RDS read replicas within same region, different az, we dont pay fees for replication, but cross region replication for RDS incurs fees.

For disaster recovery (DR) you can have a master database instance in az1 and a standby instance at az2, there are no read and writes at standby, only data from master is SYNCHRONOUSLY replicated to standby so incase master fails, standby is there to takeover as master. Read replicas can also be used as standby instance for DR. Converting RDS from single to multi az requires zero downtime. Just click on modify and choose multi-az. What would happen internally is that a snapshot of the main RDS would be taken and a read replica of it would be created in a different az, and then SYNC replication would be established between the two, with the standby eventually catching up to main.

Types of RDS are easy or standard create with production, dev/test, and free tier, you have single DB (NON-HA), Multi AZ DB (HA - but can't support reads workload properly) or Multi AZ DB cluster (HA - with read support), give identifier name, password,THen instance cconfigurations where you change instance classes like choosing ec2 family with specs, then choose storage type like i01/i02 (prod-ssd), or gp1/gp2 (non-prod. hdd), choose autoscaling with max threshold (max storage size of db), then in connectivity you can choose to connect the db to an existing ec2 or not, if not you choose the vpc, subnet, net type (ipv4), vpc sg, public ip assignment, vpc name and az choices and db port, authtication using password, password & IAM or password & kerberos authenticate, monitoring and 60-sec granurality with enhanced monitoring, give initial db name, enable/disable backups with retention period of 1-35 days. Once done install a rds client like sqlelectron, install and setup the client by entering credentials, endpoint, initial db name and connect then run queries.

RDS custom is for oracle and microsoft sql server only, and you have full access to the underlying infra, DB, OS and can activate native options, patches, and access using ssh or SSM. Take snapshot before making any changes as you would most likely break something.

Amazon Aurora is AWS propeitory software for RDS, Postgres and MySQL are both supported as Aurora DB (Your drivers will work as if Aurora was Postgres or MySQL) though you must choose one between MySQL compaitable and Postgres compaitable, its AWS Cloud optimized and has 5x performance then MySQL and 3x more than Postgres (claimed), Automatiically grows in increments of (starts from) 10GB and goes upto 128TB, can have upto 15 replicas and has faster replication than MySQL (sub 10 ms lag typically), Failover in cloud is instantaneous meaning the recovery would be faster than multi-az and its HA-native since its on cloud. Its 20% more expensive than RDS but much more efficient specially at scale.

Aurora has 6 copies of your data across 3 AZ: 4 out of 6 are needed for writes, 3 out of 6 are needed for reads, It has self-healing with peer-to-peer replications for corrupted data and storage is striped across shared storage in 100s of volumes. One aurora instance takes writes (master) Automated failover for master in less than 30 seconds. Meaning you have 1 master + 15 read replicas in which any read replica can be master in case of failover. Auto expanding is small blocks of data and supports cross-region replication. Aurora Standard is for cost-effective workloads with normal I/O while Aurora I/O optimized is for workloads with large amount of I/O operations. Instance configs are burstale and memory optimized along with Serverless v2 which doesnt ask for instance type rather asks for ACU (Aurora capacity unit) with each unit providing 2 GIB of memory and corresponding compute and networking with min 8 and max 64 acu between 0.5 to 128 in increments. Choose HA or no HA by planting a read replica of aurora in a different az. Allows Global access with global access feature enabled along with a large type of instance.

Aurora DB Cluster has two endpoints, one is writer endpoint direct from the client to the master for writes, the other is the reader endpoint which is directed from the clients to any one of the read replicas for reads via the connection loadbalancer serving as the middle-man between the client and the read replicas. Know that the loadbalancing happens at the connection level not the statement level, and auto-scaling determines amount of read replicas required. Further features of Aurora include automatic failover backup and recovery, Isolation and security, industry compliance, push-button scaling, automated patching with zero downtime, advanced monitoring, routine maintainence, and restore backups at any point and time without relying on backups

Advanced features include autoscaling when two new read replicas are created they automatically get connected to the reader endpoint.

You can also define custom endpoints for a subset of read replicas belonging to different instance family required for different task such as running analytical queires on those specific powerful read replica subset. Defining custom endpoints usually makes the reader enpoint trash and isn't used again and you then define multiple custom endpoints for each subset of replicas.

Aurora Serverless is also a advanced feature which allows automated database instantiation and auto-scaling based on actual usage, its great for infrequent or unpredictable workloads, doesnt require capacity planning and its pay per second making it a cost-effective solution. Client basically access the proxy fleet (managed by Aurora) and then replicas are created based on the workload and requirements.

Global Aurora is also a feature which is useful for disaster recovery, you can use aurora cross region read replication great for disaster recovery and simple to setup, or the recommended approach would be to use Aurora Global Database with 1 primary regions for read/write and upto 5 secondary regions for read-only where replication lag is less than 1 second, upto 16 read replicas per secondary region, helps in decreasing latency, promoting another region (for disaster recovery) has an RTO of less than 1 minute, typical cross-region replication takes less than 1 second

Aurora machine learing is the final feature which allows aurora to be integrated with AWS ML services such as AWS Sagemaker (allows any model to run on backend) and AWS Comprehend (for sentiment analysis). You don't need any ML experience, usecases are fraud targeting or product recommendations e.g Application runs a SQL query to Aurora for recommended products, Aurora gives data to AWS ML services and then they process and produce the output of recommended things like blue shirt, jeans and give it to Aurora which forwards that output to the aplication.

RDS backups are of two types, one is the automated backups where there is a full backup of the database daily (during backup window) as well as transaction logs backed up by RDS every 5 minutes, has the ability to restore at any point or time (from oldest backup to 5 minutes ago) 1 to 35 days of retention period, set 0 to disable automated backups. Manual DB Snapshots, triggered manually by the user, retention of backup as long as you want.

Trick: In a Stopped RDS database you will still pay for storage, if you plan on stopping it for a long time, you should snapshot and restore instead.

Restore your RDS DB using backup or snapshot to a new database, you can also take a snapshot of your on-prem RDS database, upload and store the snapshot to S3 and then restore a MySQL RDS database on AWS, for a Aurora MySQL DB Cluster, you would follow the same steps except the backup of your on-prem RDS DB would be taken using Percona XtraBackup.

Cloning a Aurora Database is faster than snapshot & restore, It uses copy on write protocol in which the new DB cluster follows the same data volume as the original DB cluster and additional storage is added once new data is added and data is copied to be separated. Very fast, cost effective and can be used to create staging DB from Production DB without effecting PRod DB.

RDS encryption at rest uses AWS KMS (must be defined at launch time), if master unencrypted, so are the replicas, to encrypt an unencrypted RDS DB, restore snapshot with encryption enabled. Encryption at flight (RDS/Aurora) uses AWS-TLS by default, clients must have AWS TLS Root certificates provided on AWS website. Recommended Authentication method is IAM roles instead of user:pass. Uses sg to manage traffic in/out (bound) to your DB. No SSH except for RDS custom and audit logs may be sent to CloudWatch logs for longer retention. 

RDS proxy allows app to share and pool DB connections, improving efficiency, reducing resource consumption of DB (CPU, RAM), and minimize open connections and timeouts, RDS Proxy is serverless, auto-scaling and highly available (multi-az), reduces RDS & Aurora failover time by 66%, Supports RDS (MySQL, PostgreSQL, MariaDB, MS SQL server) and Aurora (MySQL, PostgreSQL), no code changes required for most apps, just connect to RDS Proxy. Enforce IAM Authenticaton for DB and save credentials in AWS Secrets Manager. RDS Proxy is never publically accessible (must be accessed from VPC).

Lambda functions may be used from the VPC outside the private DB subnet, hundreds of functions will appear and throw connection request to RDS Proxy, overloading it. Then the proxy would pool the requests and make minimal request to the DB instance to fulfill requirements, putting less load on the DB instance and lesser connection requests.


Amazon ElastiCache is managed Cache similar to RDS, Services are managed Redis or Memcached. Caches are in-memory databases with extreme performance, low latency. Reduces load from DB for read intensive workloads and make the app statless since the state is stored in the cache. AWS take care of maintainence, patching similar to RDS. Using Elasticache however requires heavy app code changes unlike RDS Proxy to query the cache before or after you query the DB.

App queries elasticache, if data is available then it is a cache hit otherwise cache miss and data is read from DB and then written to cache, used to relieve load in RDS, invalidation strategy is used to ensure only the most current data is used in there. One example of it is user sessions to make the app stateless, the first login into the app writes data to Elasticache, then second/third time, login isn't required since data gets retrieved from cache.

Redis is HA with multi-az and autofailover, read replicas to scale reads, data is durable  using AOF persistance, backup and restore features, supports sets and sorted sets great for leaderboards and sorting data in app. 

Memcached is multi-node for partionting of data (sharding), no HA (replication), non-persistent, backup and restore (only for serverless version) and multi-threaded architecture for good performance.

Elasticache can run as serverless or self-designed, created from backup or as cluster, enabling cluster will use replication of data across multiple shards (node groups), while disabled will have a single shard (node group) with 1 master and upto 5 read replicas. Can be setup on AWS cloud and on-prem using AWS Outposts by creating a subnet ID in outposts. Check multi-az and failover if required. Choose version, port, instance family (node type) number of replicas, VPC/subnet, enable/disable encryption at rest and in-flight (in-flight requires redis AUTH token or User group Access control list), security groups.

Elasicache supports IAM authentication for Redis, IAM policies in Elasticache are only used for AWS API-level security, Redis AUTH allows you to set password/token when you create a cluster for extra security on top of sgs, supports SSL in-flight, Memcached supports SASL-based authentication (advanced).

Patterns for Elasticache:

Lazy loading: all the read data is cached, data can become stale in cache
Write through: Adds or update data in the cache when written to a DB (no stale)
Session store: store temporary session data in cache (using TTL features)

Redis Use Case:

Gaming leaderboards are computationally complex, redis sorted sets gurantee both uniqueness and element ordering, each time a new element added, its ranked in real time, then in correct order.

Points to be noted:

Aurora cloning is faster option for database replication
Only PostgreSQL and MySQL supports IAM database authentication
RDS Multi-az feature does not require you to change SQL connection string
Enhance security of Elasticache redis cluster by allowing users to access Elasticache cluster using IAM identities using IAM Authentication
Read Replica uses Asynchronous Replication and Multi-AZ uses Synchronous Replication