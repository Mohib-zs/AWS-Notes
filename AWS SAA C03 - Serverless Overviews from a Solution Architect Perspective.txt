Serverless is a paradigm where developers dont manage servers anymore, they just deploy code or functions. Intially Serverless was aka FaaS (Function as a Service) It wa pioneered by AWS Lambda but now also includes anything that's remotely managed like databases, messaging, storage etc. Serverless means you dont manage, provision and see servers. A usecases of Lambda is Users calling Rest API via AWS API Gateway to invoke Lambda to pull data from DB and present to users. Some example serverless services are Lambda, DynamoDB, Cognito, API Gateway, S3, SNS & SQS, Kinesis Data Firehose, Aurora Serverles, Step Functions, Fargate.

Lambda are virtual functions not servers, they are limited by time (used for short event based executions, min 3 sec and max is 15 min before timeout), they run on-demand, scaling is automated. Benefits of Lambda is easy pricing (you pay per request and compute time), free tier of 1,000,000 AWS Lambda requests and 400,000 GBs of compute time. Integrated with the whole AWS suite of services, Integraed with many programming languages, Easy monitoring through AWS CloudWatch, Easy to get more resources per functions (min size of function is 128 MB and goes upto 10GB of RAM per function) and increasing the RAM will also improve CPU and network. Environment variables can be stored of upto 4KB, but you may use Disk capacity in the function container (in /tmp):512 MB to 10GB. 1000 concurrent executions provided and can be increased. Lambda function for deployment size (compressed .zip) is 50MB while uncompressed deployment (code + dependencies) is 250MB, use /tmp directory to load other files at startup with more disk space and size of environment variables is 4KB.

AWS Lambda supports langs like Node.js (JavaScript), Python, Java, C# (.NET Core) / Powershell, Ruby, Custom Runtime API (community supported, example Rust or Golang). Also supports docker images but they must implement the Lambda Runtime API. ECS/Fargate is preferred for running arbitary Docker images.

Main integrations of Lambda with AWS services are API Gateway to create a REST API to invoke Lambda functions, Kinesis to perform transformations on the fly, DynamoDB to perform a function on each DB event, S3 to execute function on any event like file change, CloudFront for Lambda at edge usage, CloudWatch Events/ Eventbridge to execute some automated step whenever something occurs in our Infra like state change in code pipeline, CloudWatch Logs to stream logs wherever we want, SNS to react to notifications in your SNS topics, SQS to process messages from your SQS queues, Cognito to react whenever a user logs into our DB.

e.g is to create a serverless cron job by attaching cloudwatch eventbridge that will be triggered every one hour and every one hour it will be integrated with the Lambda function to perform your tasks.

If the exam questions you on things like, 30 min of execution is required or 30GB RAM is required or a 3GB big file is needed, know that Lambda is not the right way.

Lambda provides 1000 concurrent executions but you can set reserved concurrency at the function level (=limit). Each invocation over the concurrency limit will trigger a Throttle. Throttle behaviour for synchronous invocation = return ThrottleError - 429 while Asynchronous behaviour will retry and then go to DLQ. If you need a limit higher than 1000, raise a support ticket to AWS. The 1000 Lambda function limit is attached at the account level. e.g A usecase to understand concurrency issue is that, suppose we have a ALB with Lambda for app 01, API Gateway with Lambda for App 02 and SDK/CLI for lambda for app 03, if ALB faces huge surge and Lambda executions goes upto 1000, that is good for APP 01, but APP 02 and APP03 using Lambda will get throttled as they would not be able to perform executions.

 Concurrency with async invocations run that if the function doesnt have enough concurrency available to process all events, additional requests are throttled. For throttling errors (429) and sytem errors (500-series), Lambda returns the event to the queue and attempts to run the function again for upto 6 hours. The retry interval increases after the first attempt to a maximum of 5 minutes.

Cold Start is when you run the first instance of Lambda on your code and it takes some time, thats because code is first loaded outside the handler run (init) If the init is large (code, dependencies,SDK) this process can take some time. First request is served by new instances has higher latency than the rest. Solution for this is provisioned concurrency where concurrency is allocated befre the function is invoked, so cold start never happens. Application Auto Scaling manages concurrency (schedule or target utilization). Cold Starts have dramitaclly reduced since Oct/Nov 2019.

Unreserved concurrency is now lower than 1000 (e.g 50) though AWS raises quotas based on usage, you may request for quota increase. Reserving concurrency is important for a function, if reserved is 0 then function will be always throttled.

Lambda SnapStart improves your Lambda functions performance upto 10x at no extra cost for Java, Python & .NET. When enabled, function is invoked from a pre-intialized state. (no function intialization from scratch). When you publish a new version, Lambda intializes your function, takes a snapshot of memory and disk state of the intialized function and snapshot is cached for low-latency access.

Customization at the edge is where many modern apps execute some form of logic at the edge. An edge function is a code that you write and attach to CloudFront distributions, runs close to your users to minimize latency. CloudFront provides two types: CloudFront Functions & Lambda@Edge. No need to manage any servers, deployed globally. Use case is to customize the CDN content and pay only for what you use. Usecases are web security/privacy, Dynamic web app at edge, SEO, Intelligent routing across origins/data centers, Real-time image transformation, A/B testing User Auth, Tracking and analytics.

CloudFront Functions are lightweight functions written in JS for high scale and lag sensitive CDN customizations. Sub-ms startup times, millions of requests/second. Used to change viewer requests and responses: viewer request is after CloudFront receives a request from the viewer which we can modify or the viewer response is to modify before CloudFront forwards the response back to the viewer. Native feature of CloudFront where entire code is managed directly.

Lambda functions written in NodeJS or Python, it scales to 1000s of requests/second. Used to change/modify CloudFront requests and responses: this includes viewer request and response (like CLFront functions) and origin request (before cloudwatch forwards request to origin) and origin response after CloudFront receives the response from the origin. You must author your functions in one AWS Region (us-east-1), then cloudFront replicates to its locations. 

Lambda by default launches in AWS owned VPC not yours, can't access your private resources like RDS, Elasticache or internal DB, only public like DynamoDB. However, to launch Lambda in your VPC, you must define the VPC ID, Subnets, and the Security groups, Lambda will then create an ENI (Elastic Network Interface) in your subnets and connect to the ENI to access your internal/private VPC resources. Issues is here that Lambda functions directly access your database, they may open too many connections under high load slowing down the DB instance. RDS Proxy improves scalability by pooling and sharing DB connections, improves availability by reducing the failover time by 66% and preserving connections, improves security by enforcing IAM auth and storing creds in secrets manager. Lambda function must be deployed in your VPC because RDS proxy is never publicly accessible. 

Invoking Lambda functions from your DB instance is also possible but only for RDS for PostgreSQL and Aurora MySQL. This allows you to process data events from within a database. Though you must allow outbound traffic to your Lambda function from within your DB instance (Public, NAT GW, VPC endpoints). DB instance must have the required permissions to invoke the Lambda function (Lambda resource-based Policy and IAM Policy). e.g is when user inserts account data to DB by creating account and DB invokes Lambda function to send a welcome0 email to user via Amazon SES.

RDS event notifications tells information about the DB instance itself (create, start ,stopped) but you don't have any information about the data itself. Subscribe to the following event categories: DB instance, DB snapshot, DB parameter group, DB security group, RDS Proxy, Custom Engine version. Gives near real-time events (up to 5 minutes). It can send notification to SNS or subscribe to events using eventbridge, both of which can later invoke the Lambda function.


Amazon DynamoDB is a fully managed, highly available DB with replication across multiple AZs. NoSQL database, not a relational database and has transaction support. Millions of requests per seconds, trillions of row, 100s of TB of storage. ITs fast and consistent in performance (single-digit millisecond speed) and its integrated with IAM for security, authorization and administration. Its low cost and auto-scalling capabilities, cloud-native and requires no maintainence or patching, always available. It has standard and Infrequent access (IA) table class.

DynamoDB is made of Tables, each table has a primary key (must be decided at creation time) and each table can have an infinite number of items (=rows). Each item has attributes (can be added over time - can be null) max size of an item is 400KB, data types supported are: Scalar types - string, Number, Binary, Boolean, Null ; and Document types - List, Map ; Set Types - String Set, Number Set, Binary Set. "FOR EXAM": Great choice if your schema (how your data looks, how it's shaped) needs to rapidly evolve. In that case, DynamoDB is a much better choice than Aurora or RDS so look for this at the exam.

In DynamoDB, Primary key consists mainly the Partition Key and optionally the Sort Key (e.g User_ID, Game_ID) and second is the attributes (e.g Score, Result) attributes can be null and you can add atttributes overtime.

DynamoDB allows you to manage your table's capacity (read/write throughput). Provisioned mode (default) allows you to specify the number of reads/writes per second, you need to plan capacity beforehand, pay for provisioned read capacity units (RCU) and write capacity units (WCU). Possibility to add autoscaling mode for RCU & WCU. Great for predictable workloads which evolves smoothly and you wanna do cost-saving.

On-Demand mode allows your reads/writes to auto scale up/down with your workloads. No capacity planning needed, pay for what you use, means more expensive ($$$) great for unpredictable workloads, steep sudden spikes. Used if you have 4-5 transaction a day max because you only pay for what you use.

DynamoDB Accelerator (DAX) is a fully-managed, HA, seamless in-memory cache for DynamoDB. It helps solve read congestion by caching, microseconds latency for cached data and doesn't require application logic modification (compaitible with existing DynamoDB APIs). The cache has a 5 minute TTL. DAX cluster is the middleware b/w application and DynamoDB cluster connected to both. With DynamoDB, DAX cluster is used for individual objects cache and query & scan cache while Amazon Elasticache is used for Storing aggregation result after massive computation (which you may have run on top of DynamoDB). Though DAX Cluster is used with DynamoDB is most usecases.

AWS API Gateway allows us to create REST APIs with HTTP endpoints for clients/applications to interact with our AWS infra. API GAteway allows us to expose any AWS service to the public without exposing it directly or giving away AWS creds. (works as top layer to handle requests) but it provides alot of features. AWS Lambda + API Gateway means no infra to manage, it supports WebSocket Protocol and handles API versioning (v1, v2...) handle different environments (dev,test,prod) Handles security (Authentication and Authorization) Create API keys, handle request throttling, Swagger/Open API import to quickly define APIs, Transform and validate requests and responses, Generate SDK and API specs and cache API responses. These are a few features to keep in mind which aren't provided by a ALB.

Some great integrations include using API Gateway to invoke Lambda function, easy way to expose REST API backed by AWS LAmbda. Another is to expose HTTP endpoints in the backend, example internal HTTP API on premise, ALB etc. This helps by adding rate limiting, caching, user auth, API keys etc. Another is that it allows to expose any AWS API through the API Gateway (e.g start AWS Step Function workflow or post a message to SQS)

Another usecase is to setup API Gateway to take requests/messages from clients and send it to Kinesis data streams to store or transform records and then send it to Data Firehose to process the data and store it in S3 in .json.

API Gateway has three endpoint types, Edge-Optimized (default) for global clients where requests are routed efficiently through the CloudFront Edge locations (improves latency). The API Gateway still lives in only one region. Second is Regional for clients within the same region, could manually combine with CloudFront (more control over the caching strategies and the distribution) and final is Private which can only be accessed from your VPC using an interface VPC endpoint (ENI). Define a resource access policy to allows resources to use/access API Gateway.

API Gateway security includes user auth via IAM Roles (for internal apps running on EC2 or other such service), Cognito (identity for external users e.g webapp/mobile users) or custom Authorizer (auth via own logic using Lambda). Another is custom domain name HTTPS security through integration with AWS Certificate Manager (ACM) If using Edge-optimized endpoint, then the certificate must be in us-east-1. If using regional endpoint, the certificate must be in the API Gateway region, and must setup CNAME or A-alias record in route 53. 


AWS Step Functions are use to build or visualize serverless workflow which are difficult to describe and also orchestrate your Lambda functions. Features include sequence, parallel, conditions, timeouts, error handling. Can integrate with EC2, ECS, On-prem servers, API-gateway, SQS queues etc. Possibility of implementing human approval feature and use cases are order fulfillment, data processing, web apps, or any workflow.

Amazon Cognito gives users an identity to interact with our web or mobile application, cognito user pools provide sign in functionality for app users, easy integration with API gateway & Application Load Balancer.

Cognito Identity Pools (prev. Federated Identity) provides temporary AWS creds to users so they can access AWS resources directly, they integrate with Cognito Users pools as an identity provider. Users can be Cognito user pools, 3rd party logins etc. Users then access AWS services directly through API GW, IAM policies are applied to the creds that are defined in cognito, policies are customized for each user_id creds for fine grain control. Default IAM roles for authenticated and guest users which don't have a specific role created for them. In Cognito vs IAM, in exam, keywords for cognito are "hundreds of users", "mobile users", "authenticate with SAML or other such method"

Cognito User Polls (CUP) - User features: it creates a serverless database of user for your web & mobile apps, Simple login: Username (or email) with password combo, Password reset and MFA provided alongside Email & Phone Number Verification. Federated Identities (Login with..) for users from Facebook, Google, SAML, OpenID etc.

CUP integrates with API Gateway and ALB, the workflow starts with the client/application which logs into (authenticate) Cognito User Pools, after authentication, cognito provides a token to app, app then provides token to API Gateway, API GW evaluates the token integrity and the identity of user with Cognito, once confirmed then API GW forwards request to Backend (Lambda) which then provides the content specific for that very user. Same can be done with ALB as well.

Cognito ID pools enable row level security in DynamoDB, meaning user can only read specific rows of the db not all via policy.


IMP POINTS:

To authenticate users at edge without having their requests go to origin, use Lambda@Edge

To increase the Read Throughput for DynamoDB for an upcoming Christmas sale and to reduce throttling, use DAX cluster

If an app uses DynamoDB as its datastore and you want to automate sending welcome mail to new users after sign up, enable DynamoDB streams and configure it to invoke Lambda to send emails.

You can scale RCU and WCU independently, one is not dependent on another.

DynamoDB provides TTL for users sessions and logins to expire.

size of an item in DynamoDB table is 400KB

DynamoDB tables can be exported directly to S3 as .json files.