Serverless is a paradigm where developers dont manage servers anymore, they just deploy code or functions. Intially Serverless was aka FaaS (Function as a Service) It wa pioneered by AWS Lambda but now also includes anything that's remotely managed like databases, messaging, storage etc. Serverless means you dont manage, provision and see servers. A usecases of Lambda is Users calling Rest API via AWS API Gateway to invoke Lambda to pull data from DB and present to users. Some example serverless services are Lambda, DynamoDB, Cognito, API Gateway, S3, SNS & SQS, Kinesis Data Firehose, Aurora Serverles, Step Functions, Fargate.

Lambda are virtual functions not servers, they are limited by time (used for short event based executions, min 3 sec and max is 15 min before timeout), they run on-demand, scaling is automated. Benefits of Lambda is easy pricing (you pay per request and compute time), free tier of 1,000,000 AWS Lambda requests and 400,000 GBs of compute time. Integrated with the whole AWS suite of services, Integraed with many programming languages, Easy monitoring through AWS CloudWatch, Easy to get more resources per functions (min size of function is 128 MB and goes upto 10GB of RAM per function) and increasing the RAM will also improve CPU and network. Environment variables can be stored of upto 4KB, but you may use Disk capacity in the function container (in /tmp):512 MB to 10GB. 1000 concurrent executions provided and can be increased. Lambda function for deployment size (compressed .zip) is 50MB while uncompressed deployment (code + dependencies) is 250MB, use /tmp directory to load other files at startup with more disk space and size of environment variables is 4KB.

AWS Lambda supports langs like Node.js (JavaScript), Python, Java, C# (.NET Core) / Powershell, Ruby, Custom Runtime API (community supported, example Rust or Golang). Also supports docker images but they must implement the Lambda Runtime API. ECS/Fargate is preferred for running arbitary Docker images.

Main integrations of Lambda with AWS services are API Gateway to create a REST API to invoke Lambda functions, Kinesis to perform transformations on the fly, DynamoDB to perform a function on each DB event, S3 to execute function on any event like file change, CloudFront for Lambda at edge usage, CloudWatch Events/ Eventbridge to execute some automated step whenever something occurs in our Infra like state change in code pipeline, CloudWatch Logs to stream logs wherever we want, SNS to react to notifications in your SNS topics, SQS to process messages from your SQS queues, Cognito to react whenever a user logs into our DB.

e.g is to create a serverless cron job by attaching cloudwatch eventbridge that will be triggered every one hour and every one hour it will be integrated with the Lambda function to perform your tasks.

If the exam questions you on things like, 30 min of execution is required or 30GB RAM is required or a 3GB big file is needed, know that Lambda is not the right way.

Lambda provides 1000 concurrent executions but you can set reserved concurrency at the function level (=limit). Each invocation over the concurrency limit will trigger a Throttle. Throttle behaviour for synchronous invocation = return ThrottleError - 429 while Asynchronous behaviour will retry and then go to DLQ. If you need a limit higher than 1000, raise a support ticket to AWS. The 1000 Lambda function limit is attached at the account level. e.g A usecase to understand concurrency issue is that, suppose we have a ALB with Lambda for app 01, API Gateway with Lambda for App 02 and SDK/CLI for lambda for app 03, if ALB faces huge surge and Lambda executions goes upto 1000, that is good for APP 01, but APP 02 and APP03 using Lambda will get throttled as they would not be able to perform executions.

 Concurrency with async invocations run that if the function doesnt have enough concurrency available to process all events, additional requests are throttled. For throttling errors (429) and sytem errors (500-series), Lambda returns the event to the queue and attempts to run the function again for upto 6 hours. The retry interval increases after the first attempt to a maximum of 5 minutes.

Cold Start is when you run the first instance of Lambda on your code and it takes some time, thats because code is first loaded outside the handler run (init) If the init is large (code, dependencies,SDK) this process can take some time. First request is served by new instances has higher latency than the rest. Solution for this is provisioned concurrency where concurrency is allocated befre the function is invoked, so cold start never happens. Application Auto Scaling manages concurrency (schedule or target utilization). Cold Starts have dramitaclly reduced since Oct/Nov 2019.

Unreserved concurrency is now lower than 1000 (e.g 50) though AWS raises quotas based on usage, you may request for quota increase. Reserving concurrency is important for a function, if reserved is 0 then function will be always throttled.

Lambda SnapStart improves your Lambda functions performance upto 10x at no extra cost for Java, Python & .NET. When enabled, function is invoked from a pre-intialized state. (no function intialization from scratch). When you publish a new version, Lambda intializes your function, takes a snapshot of memory and disk state of the intialized function and snapshot is cached for low-latency access.

Customization at the edge is where many modern apps execute some form of logic at the edge. An edge function is a code that you write and attach to CloudFront distributions, runs close to your users to minimize latency. CloudFront provides two types: CloudFront Functions & Lambda@Edge. No need to manage any servers, deployed globally. Use case is to customize the CDN content and pay only for what you use. Usecases are web security/privacy, Dynamic web app at edge, SEO, Intelligent routing across origins/data centers, Real-time image transformation, A/B testingm User Auth, Tracking and analytics. 
CloudFront Functions are lightweight functions written in JS for high scale and lag sensitive CDN customizations. Sub-ms startup times, millions of requests/second. Used to change viewer requests and responses: viewer request is after CloudFront receives a request from the viewer which we can modify or the viewer response is to modify before CloudFront forwards the response back to the viewer. Native feature of CloudFront where entire code is managed directly.

Lambda functions written in NodeJS or Python, it scales to 1000s of requests/second. Used to change/modify CloudFront requests and responses: this includes viewer request and response (like CLFront functions) and origin request (before cloudwatch forwards request to origin) and origin response after CloudFront receives the response from the origin. You must author your functions in one AWS Region (us-east-1), then cloudFront replicates to its locations. 


